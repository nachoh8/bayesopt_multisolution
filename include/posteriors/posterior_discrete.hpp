/**  \file posterior_discrete.hpp \brief Posterior distribution on GPs
     based on grid sampling over kernel parameters */
/*
-------------------------------------------------------------------------
   This file is part of BayesOpt, an efficient C++ library for
   Bayesian optimization.

   Copyright (C) 2011-2014 Ruben Martinez-Cantin <rmcantin@unizar.es>

   BayesOpt is free software: you can redistribute it and/or modify it
   under the terms of the GNU General Public License as published by
   the Free Software Foundation, either version 3 of the License, or
   (at your option) any later version.

   BayesOpt is distributed in the hope that it will be useful, but
   WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with BayesOpt.  If not, see <http://www.gnu.org/licenses/>.
------------------------------------------------------------------------
*/


#ifndef  _POSTERIOR_DISCRETE_HPP_
#define  _POSTERIOR_DISCRETE_HPP_

#include <boost/ptr_container/ptr_vector.hpp>
#include "criteria/criteria_functors.hpp"
#include "posteriors/posterior_model.hpp"


namespace bayesopt {

  /**
   * \brief Posterior model of nonparametric processes/criteria based
   * on grid sampling.
   *
   * For computational reasons we store a copy of each conditional
   * models with the corresponding sample generated by the grid. That
   * is to avoid costly operations like matrix inversions for every
   * kernel parameter in a GP prediction. Thus, we assume that the
   * number of particles is not very large.
   */
  class GridModel: public PosteriorModel
  {
  public:

    typedef boost::ptr_vector<NonParametricProcess>  GPVect;
    typedef boost::ptr_vector<Criteria>  CritVect;

    /**
     * \brief Constructor (Note: default constructor is private)
     *
     * @param dim number of input dimensions
     * @param params configuration parameters (see parameters.hpp)
     * @param eng random number generation engine (boost)
     */
    GridModel(size_t dim, Parameters params, randEngine& eng);

    virtual ~GridModel();

    void setGridBounds(const vectord& lb, const vectord& up)

    void updateHyperParameters();
    void fitSurrogateModel();
    void updateSurrogateModel();

    double evaluateCriteria(const vectord& query);
    void updateCriteria(const vectord& query);

    bool criteriaRequiresComparison();
    void setFirstCriterium();
    bool setNextCriterium(const vectord& prevResult);
    std::string getBestCriteria(vectord& best);

    ProbabilityDistribution* getPrediction(const vectord& query);

  private:
    void setSurrogateModel(randEngine& eng);
    void setCriteria(randEngine& eng);
    double getParameterInformationGain(const vectord& query);

  private:  // Members
    size_t nParticles;
    GPVect mGP;                ///< Pointer to surrogate model
    CritVect mCrit;                    ///< Metacriteria model
    vectord mWeights;         ///< Weight of each model sample
    size_t mIterAnnealing;
    double mCoefAnnealing;


  private: //Forbidden
    GridModel();
    GridModel(GridModel& copy);
  };

  /**@}*/

  inline void GridModel::fitSurrogateModel()
  {
    for(GPVect::iterator it=mGP.begin(); it != mGP.end(); ++it)
      it->fitSurrogateModel();
  };

  inline void GridModel::updateSurrogateModel()
  {
    for(GPVect::iterator it=mGP.begin(); it != mGP.end(); ++it)
      it->updateSurrogateModel();
  };

  inline double GridModel::evaluateCriteria(const vectord& query)
  {
    double sum = 0.0;
    for(CritVect::iterator it=mCrit.begin(); it != mCrit.end(); ++it)
      {
	sum += it->evaluate(query);
      }
    double active_term = 0.0;
    if (mCoefAnnealing > 0.0)
      {
	active_term = mCoefAnnealing/(mIterAnnealing*mIterAnnealing) * getParameterInformationGain(query);
      }
    return sum/static_cast<double>(nParticles) - active_term;

  };

  inline void GridModel::updateCriteria(const vectord& query)
  {
    mIterAnnealing++;
    for(CritVect::iterator it=mCrit.begin(); it != mCrit.end(); ++it)
      {
	it->update(query);
      }
  };


  inline bool GridModel::criteriaRequiresComparison()
  {return mCrit[0].requireComparison(); };

  inline void GridModel::setFirstCriterium()
  {
    for(CritVect::iterator it=mCrit.begin(); it != mCrit.end(); ++it)
      {
	it->initialCriteria();
      }
  };

  // Although we change the criteria for all MCMC particles, we use
  // only the first element to compute de Hedge algorithm, because it
  // should be based on the average result, thus being common for all
  // the particles.
  inline bool GridModel::setNextCriterium(const vectord& prevResult)
  {
    bool rotated;
    mCrit[0].pushResult(prevResult);
    for(CritVect::iterator it=mCrit.begin(); it != mCrit.end(); ++it)
      {
	rotated = it->rotateCriteria();
      }
    return rotated;
  };

  inline std::string GridModel::getBestCriteria(vectord& best)
  { return mCrit[0].getBestCriteria(best); };

  inline
  ProbabilityDistribution* GridModel::getPrediction(const vectord& query)
  {
    return mGP[0].prediction(query);
  }

  inline 
  double MCMCModel::getPredictionMean(const vectord& query)
  {
    double mean = 0;
    size_t len = static_cast<double>(mGP.size());
    
    for(size_t i = 0; i < len; ++i)
      {
        mean += mWeights[i] * mGP[i]->prediction(query)->mean();
      }
    return mean;

  // What we want here is
  // log(sum(w_i (m_i - m)^2 + s_i^2)) - sum(w_i log(s_i^2))

  inline
  double GridModel::getParameterInformationGain(const vectord& query)
  {

    double mean = 0.0, std = 0.0;
    vectord mi(nParticles);
    vectord s2i(nParticles);
    for(size_t i = 0; i<nParticles; ++i)
      {
	ProbabilityDistribution* d = mGP[i].prediction(query);
	mi(i) = d->mean();
	s2i(i) = d->std()*d->std();
	mean += mi(i);
      }
    mean /= nParticles;
    double sum1 = 0.0, sum2 = 0.0;
    for(size_t i = 0; i<nParticles; ++i)
      {
	sum1 += (mi(i)-mean)*(mi(i)-mean) + s2i(i);
	sum2 += log(s2i(i));
      }
    sum1 /= nParticles; sum2 /= nParticles;   // We asume all w_i = 1/n
    return log(sum1) - sum2;
  };



} //namespace bayesopt


#endif
